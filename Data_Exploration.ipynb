{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull traffic data from Chicago City Data API\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import downloaded csv file\n",
    "crashes_csv = \"Traffic_Crashes.csv\"\n",
    "traffic_crashes = pd.read_csv(crashes_csv)\n",
    "crashes_df = pd.DataFrame(traffic_crashes)\n",
    "crashes_drop_df = crashes_df.dropna(subset=['LATITUDE', 'LONGITUDE'], how='all')\n",
    "crashes_drop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_drop_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to only columns we care about\n",
    "crashes_drop_df = crashes_drop_df[['CRASH_DATE', 'WEATHER_CONDITION', 'LIGHTING_CONDITION',\n",
    "                                   'STREET_NO', 'STREET_DIRECTION', 'STREET_NAME', 'FIRST_CRASH_TYPE','PRIM_CONTRIBUTORY_CAUSE',\n",
    "                                   'INJURIES_TOTAL','INJURIES_FATAL', 'CRASH_HOUR','CRASH_DAY_OF_WEEK',\n",
    "                                   'CRASH_MONTH', 'LATITUDE', 'LONGITUDE', 'LOCATION']]\n",
    "\n",
    "\n",
    "# Reformat the date column to be easily comparable dates\n",
    "crashes_drop_df['CRASH_DATE'] = pd.to_datetime(crashes_drop_df['CRASH_DATE'])\n",
    "crashes_drop_df.sort_values(by='CRASH_DATE', ascending=False)\n",
    "\n",
    "# Cut Lat and Lon to 4 decimal places\n",
    "# crashes_drop_df['LATITUDE'] = crashes_drop_df['LATITUDE'].round(3)\n",
    "# crashes_drop_df['LONGITUDE'] = crashes_drop_df['LONGITUDE'].round(3)\n",
    "\n",
    "\n",
    "# Filter the data frame for only dates 2018 onward\n",
    "\n",
    "crashes_2017_18 = crashes_drop_df.loc[(crashes_drop_df['CRASH_DATE'] >= \"2017-01-01\") & \n",
    "                                        (crashes_drop_df['CRASH_DATE'] <= \"2018-12-31\"), :]\n",
    "\n",
    "crashes_2017_18.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a data frame with the Chicago population from 2015 to 2019\n",
    "\n",
    "pop_years = [2014, 2015, 2016, 2017, 2018]\n",
    "chi_pops = [2728524, 2726215, 2718946, 2713067, 2705994]\n",
    "chi_yearly_pops = {\"Year\": pop_years, \"Chicago Population\": chi_pops}\n",
    "\n",
    "chicago_pop_df = pd.DataFrame(chi_yearly_pops)\n",
    "chicago_pop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter original dataframe for only crashes with a fatality\n",
    "fatal_crashes = crashes_2017_18.loc[(crashes_2017_18['INJURIES_FATAL'] > 0), :]\n",
    "\n",
    "fatal_groupby = fatal_crashes.groupby(['FIRST_CRASH_TYPE', 'LIGHTING_CONDITION'])\n",
    "fatal_groupby.count().sort_values(by='Crash Date', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Rideshare CSV\n",
    "rideshare_csv = \"rs_filter_csv.csv\"\n",
    "rideshare_data = pd.read_csv(rideshare_csv)\n",
    "rideshare_df = pd.DataFrame(rideshare_data)\n",
    "\n",
    "rideshare_df = rideshare_df[['Month', 'NUMBER_OF_TRIPS_2015', 'NUMBER_OF_TRIPS_2016', 'NUMBER_OF_TRIPS_2017',\n",
    "                            'NUMBER_OF_TRIPS_2018']]\n",
    "\n",
    "rideshare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round crashes_2017_18 to three decimals, and merge with speed cam data\n",
    "\n",
    "crashes_2017_18['LATITUDE'] = crashes_2017_18['LATITUDE'].round(3)\n",
    "crashes_2017_18['LONGITUDE'] = crashes_2017_18['LONGITUDE'].round(3)\n",
    "\n",
    "accidents_speedcams = crashes_2017_18.merge(speed_df, how=\"inner\", on=('LATITUDE', 'LONGITUDE'))\n",
    "accidents_speedcams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_speedcams.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select desired columns and filter on 2017 and 2018\n",
    "accidents_speedcams = accidents_speedcams[['Crash Date', 'STREET_NO', 'STREET_DIRECTION', 'STREET_NAME', 'FIRST_CRASH_TYPE',\n",
    "                                           'INJURIES_TOTAL', 'PRIM_CONTRIBUTORY_CAUSE', 'INJURIES_FATAL',\n",
    "                                           'CRASH_HOUR', 'CRASH_DAY_OF_WEEK', 'CRASH_MONTH', 'LATITUDE',\n",
    "                                           'LONGITUDE', 'CAMERA ID', 'VIOLATIONS', 'VIOLATION DATE']]\n",
    "\n",
    "accidents_speedcams = accidents_speedcams.loc[(accidents_speedcams['Crash Date'] >= pd.to_datetime(\"2017-01-01\").date()) & \n",
    "                                        (accidents_speedcams['Crash Date'] <= pd.to_datetime(\"2018-12-31\").date()), :]\n",
    "\n",
    "accidents_speedcams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group crashes by their proximity to speed cameras\n",
    "accidents_cameras_group = accidents_speedcams.groupby(['CAMERA ID'])\n",
    "accidents_cameras_count = acc_speed_group.nunique().sort_values(by='Crash Date', ascending=False)\n",
    "\n",
    "accidents_cameras_count = accidents_cameras_count[['Crash Date']] \n",
    "accidents_cameras_count.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed camera\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "import datetime\n",
    "import gmaps\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.lines as mlines\n",
    "import gmaps.datasets\n",
    "import scipy.stats as stats\n",
    "import folium\n",
    "from folium import plugins\n",
    "import seaborn as sns; sns.set()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>CAMERA ID</th>\n",
       "      <th>VIOLATION DATE</th>\n",
       "      <th>VIOLATIONS</th>\n",
       "      <th>X COORDINATE</th>\n",
       "      <th>Y COORDINATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Historical Wards 2003-2015</th>\n",
       "      <th>Zip Codes</th>\n",
       "      <th>Community Areas</th>\n",
       "      <th>Census Tracts</th>\n",
       "      <th>Wards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10318 S INDIANAPOLIS</td>\n",
       "      <td>CHI120</td>\n",
       "      <td>06/10/2019</td>\n",
       "      <td>83</td>\n",
       "      <td>1.203645e+06</td>\n",
       "      <td>1.837056e+06</td>\n",
       "      <td>41.707577</td>\n",
       "      <td>-87.529848</td>\n",
       "      <td>(41.70757690291348, -87.52984826112849)</td>\n",
       "      <td>47.0</td>\n",
       "      <td>21202.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1110 S PULASKI RD</td>\n",
       "      <td>CHI163</td>\n",
       "      <td>06/10/2019</td>\n",
       "      <td>23</td>\n",
       "      <td>1.149841e+06</td>\n",
       "      <td>1.894931e+06</td>\n",
       "      <td>41.867603</td>\n",
       "      <td>-87.725383</td>\n",
       "      <td>(41.86760272243294, -87.7253827433152)</td>\n",
       "      <td>36.0</td>\n",
       "      <td>21572.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1111 N HUMBOLDT</td>\n",
       "      <td>CHI010</td>\n",
       "      <td>06/10/2019</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11144 S VINCENNES</td>\n",
       "      <td>CHI023</td>\n",
       "      <td>06/10/2019</td>\n",
       "      <td>34</td>\n",
       "      <td>1.166994e+06</td>\n",
       "      <td>1.830711e+06</td>\n",
       "      <td>41.691025</td>\n",
       "      <td>-87.664248</td>\n",
       "      <td>(41.69102545584918, -87.6642476900556)</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22212.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11153 S VINCENNES</td>\n",
       "      <td>CHI022</td>\n",
       "      <td>06/10/2019</td>\n",
       "      <td>10</td>\n",
       "      <td>1.167029e+06</td>\n",
       "      <td>1.830594e+06</td>\n",
       "      <td>41.690702</td>\n",
       "      <td>-87.664122</td>\n",
       "      <td>(41.690701951255015, -87.66412238501842)</td>\n",
       "      <td>45.0</td>\n",
       "      <td>22212.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ADDRESS CAMERA ID VIOLATION DATE  VIOLATIONS  X COORDINATE  \\\n",
       "0  10318 S INDIANAPOLIS    CHI120     06/10/2019          83  1.203645e+06   \n",
       "1     1110 S PULASKI RD    CHI163     06/10/2019          23  1.149841e+06   \n",
       "2       1111 N HUMBOLDT    CHI010     06/10/2019          44           NaN   \n",
       "3     11144 S VINCENNES    CHI023     06/10/2019          34  1.166994e+06   \n",
       "4     11153 S VINCENNES    CHI022     06/10/2019          10  1.167029e+06   \n",
       "\n",
       "   Y COORDINATE   LATITUDE  LONGITUDE  \\\n",
       "0  1.837056e+06  41.707577 -87.529848   \n",
       "1  1.894931e+06  41.867603 -87.725383   \n",
       "2           NaN        NaN        NaN   \n",
       "3  1.830711e+06  41.691025 -87.664248   \n",
       "4  1.830594e+06  41.690702 -87.664122   \n",
       "\n",
       "                                   LOCATION  Historical Wards 2003-2015  \\\n",
       "0   (41.70757690291348, -87.52984826112849)                        47.0   \n",
       "1    (41.86760272243294, -87.7253827433152)                        36.0   \n",
       "2                                       NaN                         NaN   \n",
       "3    (41.69102545584918, -87.6642476900556)                        33.0   \n",
       "4  (41.690701951255015, -87.66412238501842)                        45.0   \n",
       "\n",
       "   Zip Codes  Community Areas  Census Tracts  Wards  \n",
       "0    21202.0             49.0          705.0   47.0  \n",
       "1    21572.0             30.0           98.0   14.0  \n",
       "2        NaN              NaN            NaN    NaN  \n",
       "3    22212.0             74.0          378.0   42.0  \n",
       "4    22212.0             74.0          378.0   22.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read dataframe\n",
    "speed_df = pd.read_csv('Speed_Camera_Violations.csv')\n",
    "speed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to datetime, then drop NaN\n",
    "speed_df['VIOLATION DATE'] = pd.to_datetime(speed_df['VIOLATION DATE'])\n",
    "speed_df_drop = speed_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH_REPORTED</th>\n",
       "      <th>NUMBER_OF_TRIPS_2015</th>\n",
       "      <th>NUMBER_OF_TRIPS_2016</th>\n",
       "      <th>NUMBER_OF_TRIPS_2017</th>\n",
       "      <th>NUMBER_OF_TRIPS_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>518539</td>\n",
       "      <td>1733583</td>\n",
       "      <td>3582540</td>\n",
       "      <td>4842911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>518539</td>\n",
       "      <td>1732573</td>\n",
       "      <td>3455601</td>\n",
       "      <td>4718735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>712521</td>\n",
       "      <td>1887034</td>\n",
       "      <td>4017804</td>\n",
       "      <td>5284216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>764487</td>\n",
       "      <td>2014292</td>\n",
       "      <td>3839776</td>\n",
       "      <td>3500907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>868650</td>\n",
       "      <td>2184055</td>\n",
       "      <td>4039394</td>\n",
       "      <td>3580748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH_REPORTED  NUMBER_OF_TRIPS_2015  NUMBER_OF_TRIPS_2016  \\\n",
       "0               1                518539               1733583   \n",
       "1               2                518539               1732573   \n",
       "2               3                712521               1887034   \n",
       "3               4                764487               2014292   \n",
       "4               5                868650               2184055   \n",
       "\n",
       "   NUMBER_OF_TRIPS_2017  NUMBER_OF_TRIPS_2018  \n",
       "0               3582540               4842911  \n",
       "1               3455601               4718735  \n",
       "2               4017804               5284216  \n",
       "3               3839776               3500907  \n",
       "4               4039394               3580748  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uber dataframe\n",
    "uber_df = pd.read_csv('rs_filter_csv.csv')\n",
    "uber_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\consi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  \n",
      "C:\\Users\\consi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\consi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\consi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  \"\"\"\n",
      "C:\\Users\\consi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# filtered by date\n",
    "speed_18 = speed_df_drop[(speed_df_drop['VIOLATION DATE']>=datetime.date(2018,1,1)) & (speed_df_drop['VIOLATION DATE']<=datetime.date(2018,12,31))]\n",
    "speed_17 = speed_df_drop[(speed_df_drop['VIOLATION DATE']>=datetime.date(2017,1,1)) & (speed_df_drop['VIOLATION DATE']<=datetime.date(2017,12,31))]\n",
    "speed_16 = speed_df_drop[(speed_df_drop['VIOLATION DATE']>=datetime.date(2016,1,1)) & (speed_df_drop['VIOLATION DATE']<=datetime.date(2016,12,31))]\n",
    "speed_15 = speed_df_drop[(speed_df_drop['VIOLATION DATE']>=datetime.date(2015,1,1)) & (speed_df_drop['VIOLATION DATE']<=datetime.date(2015,12,31))]\n",
    "speed_14 = speed_df_drop[(speed_df_drop['VIOLATION DATE']>=datetime.date(2014,1,1)) & (speed_df_drop['VIOLATION DATE']<=datetime.date(2014,12,31))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupby\n",
    "speed_camera_18 = speed_18.groupby(['CAMERA ID','LATITUDE','LONGITUDE'])\n",
    "speed_camera_17 = speed_17.groupby(['CAMERA ID','LATITUDE','LONGITUDE'])\n",
    "speed_camera_16 = speed_16.groupby(['CAMERA ID','LATITUDE','LONGITUDE'])\n",
    "speed_camera_15 = speed_15.groupby(['CAMERA ID','LATITUDE','LONGITUDE'])\n",
    "speed_camera_14 = speed_14.groupby(['CAMERA ID','LATITUDE','LONGITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort18\n",
    "sorted_speed_18 = speed_camera_18[\"VIOLATIONS\"].sum().sort_values(ascending=False).reset_index()\n",
    "top_20_18 = sorted_speed_18.head(20)\n",
    "#sort17\n",
    "sorted_speed_17 = speed_camera_17[\"VIOLATIONS\"].sum().sort_values(ascending=False).reset_index()\n",
    "top_20_17 = sorted_speed_17.head(20)\n",
    "#sort16\n",
    "sorted_speed_16 = speed_camera_16[\"VIOLATIONS\"].sum().sort_values(ascending=False).reset_index()\n",
    "top_20_16 = sorted_speed_16.head(20)\n",
    "#sort15\n",
    "sorted_speed_15 = speed_camera_15[\"VIOLATIONS\"].sum().sort_values(ascending=False).reset_index()\n",
    "top_20_15 = sorted_speed_15.head(20)\n",
    "#sort14\n",
    "sorted_speed_14 = speed_camera_14[\"VIOLATIONS\"].sum().sort_values(ascending=False).reset_index()\n",
    "top_20_14 = sorted_speed_14.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>630856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1157460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1077135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>976290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>927820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "2014   630856\n",
       "2015  1157460\n",
       "2016  1077135\n",
       "2017   976290\n",
       "2018   927820"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total violations per year\n",
    "violations_18 = sorted_speed_18['VIOLATIONS'].sum()\n",
    "violations_17 = sorted_speed_17['VIOLATIONS'].sum()\n",
    "violations_16 = sorted_speed_16['VIOLATIONS'].sum()\n",
    "violations_15 = sorted_speed_15['VIOLATIONS'].sum()\n",
    "violations_14 = sorted_speed_14['VIOLATIONS'].sum()\n",
    "#total violations dataframe\n",
    "total_violations = pd.DataFrame({\n",
    "    '2014':[violations_14],\n",
    "    '2015':[violations_15],\n",
    "    '2016':[violations_16],\n",
    "    '2017':[violations_17],\n",
    "    '2018':[violations_18]\n",
    "})\n",
    "vio = total_violations.T\n",
    "vio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015    1157460.0\n",
      "2016    1077135.0\n",
      "2017     976290.0\n",
      "2018     927820.0\n",
      "dtype: float64\n",
      "2015    11052156.0\n",
      "2016    29898808.0\n",
      "2017    48857182.0\n",
      "2018    57779874.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#uber and total violation dataframe\n",
    "\n",
    "uber_total_15 = uber_df['NUMBER_OF_TRIPS_2015'].sum() \n",
    "uber_total_16 = uber_df['NUMBER_OF_TRIPS_2016'].sum() \n",
    "uber_total_17 = uber_df['NUMBER_OF_TRIPS_2017'].sum() \n",
    "uber_total_18 = uber_df['NUMBER_OF_TRIPS_2018'].sum() \n",
    "uber_total = pd.DataFrame({\n",
    "    '2015':[uber_total_15],\n",
    "    '2016':[uber_total_16],\n",
    "    '2017':[uber_total_17],\n",
    "    '2018': [uber_total_18]\n",
    "})\n",
    "\n",
    "violation_total = pd.DataFrame({\n",
    "    \n",
    "    '2015':[violations_15],\n",
    "    '2016':[violations_16],\n",
    "    '2017':[violations_17],\n",
    "    '2018':[violations_18]\n",
    "})\n",
    "print(violation_total.mean())\n",
    "print(uber_total.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line graph data\n",
    "speed_camera_18_date = speed_18.groupby(['VIOLATION DATE'])\n",
    "\n",
    "date_18 = speed_camera_18_date['VIOLATIONS'].sum().reset_index()\n",
    "\n",
    "speed_camera_17_date = speed_17.groupby(['VIOLATION DATE'])\n",
    "\n",
    "date_17 = speed_camera_17_date['VIOLATIONS'].sum().reset_index()\n",
    "\n",
    "speed_camera_16_date = speed_16.groupby(['VIOLATION DATE'])\n",
    "\n",
    "date_16 = speed_camera_16_date['VIOLATIONS'].sum().reset_index()\n",
    "\n",
    "speed_camera_15_date = speed_15.groupby(['VIOLATION DATE'])\n",
    "\n",
    "date_15 = speed_camera_15_date['VIOLATIONS'].sum().reset_index()\n",
    "\n",
    "speed_camera_14_date = speed_14.groupby(['VIOLATION DATE'])\n",
    "\n",
    "date_14 = speed_camera_14_date['VIOLATIONS'].sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map info total\n",
    "total_group = speed_df.groupby(['CAMERA ID','LATITUDE','LONGITUDE'])\n",
    "violations_total = total_group['VIOLATIONS'].sum().reset_index()\n",
    "\n",
    "locations_total= violations_total[[\"LATITUDE\",\"LONGITUDE\"]]\n",
    "rating_total =violations_total[\"VIOLATIONS\"].astype(float)\n",
    "\n",
    "chicago_center = (41.8781,-87.6298)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 cameras from 2014\n",
    "top_20 = top_20_14['CAMERA ID'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 20 cameras from 2014 merged into the 2015 through 2018\n",
    "\n",
    "merger_15 = sorted_speed_15.merge(top_20, how = 'inner').sort_values('VIOLATIONS')\n",
    "merger_16 = sorted_speed_16.merge(top_20, how = 'inner').sort_values('VIOLATIONS')\n",
    "merger_17 = sorted_speed_17.merge(top_20, how = 'inner').sort_values('VIOLATIONS')\n",
    "merger_18 = sorted_speed_18.merge(top_20, how = 'inner').sort_values('VIOLATIONS')\n",
    "merg_15 = merger_15.rename(columns = ({'VIOLATIONS':'Violations_2015'}))\n",
    "merg_16 = merger_16.rename(columns = ({'VIOLATIONS':'Violations_2016'}))\n",
    "merg_17 = merger_17.rename(columns = ({'VIOLATIONS':'Violations_2017'}))\n",
    "merg_18 = merger_18.rename(columns = ({'VIOLATIONS':'Violations_2018'}))\n",
    "\n",
    "#form into a dataframe\n",
    "\n",
    "top = top_20_14.rename(columns= {'VIOLATIONS':'Violations_2014'}).sort_values('Violations_2014')\n",
    "violations_1 = top.merge(merg_15, how='inner')\n",
    "violations_11 = violations_1.merge(merg_16, how = 'inner')\n",
    "violations_111 = violations_11.merge(merg_17, how = 'inner')\n",
    "violations_final = violations_111.merge(merg_18, how = 'inner')\n",
    "violations_final['Total']=violations_final['Violations_2014']+violations_final['Violations_2015']+violations_final['Violations_2016']+violations_final['Violations_2017']+violations_final['Violations_2018']\n",
    "violations_finals = violations_final.sort_values('Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015    1157460.0\n",
      "2016    1077135.0\n",
      "2017     976290.0\n",
      "2018     927820.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2726215\n",
       "1    2718946\n",
       "2    2713067\n",
       "3    2705994\n",
       "Name: Pop, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = 2015,2016,2017,2018\n",
    "chi_pops = [2726215, 2718946, 2713067, 2705994]\n",
    "\n",
    "chicago_pop_df = pd.DataFrame({\n",
    "    'Year':years,\n",
    "    'Pop':chi_pops\n",
    "})\n",
    "\n",
    "\n",
    "print(violation_total.mean())\n",
    "chicago_pop_df['Pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9880440201257168, 0.011955979874283209)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(chicago_pop_df['Pop'], violation_total.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.9984176655162007, 0.0015823344837992976)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(uber_total.mean(),violation_total.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
